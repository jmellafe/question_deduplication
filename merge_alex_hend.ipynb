{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "merge_alex_hend.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jmellafe/question_deduplication/blob/master/merge_alex_hend.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vC7iDHe9BcUD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import seaborn as sns\n",
        "from matplotlib import pyplot as plt\n",
        "import pandas as pd\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from gensim.corpora import Dictionary\n",
        "from gensim.models import TfidfModel, KeyedVectors\n",
        "from collections import Counter\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "from sklearn.metrics import log_loss\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "from sklearn.svm import LinearSVC\n",
        "import sklearn.svm as svm\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "pd.options.mode.chained_assignment = None # To avoid warnings"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pCs7aRwYBqi2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "168e831b-b1db-4243-8280-0838fd9f002c"
      },
      "source": [
        "# import data from the drive \n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive', force_remount=True)\n",
        "root_path = '/content/gdrive/My Drive/KTH courses/P4/NLP Language processing/project/data/train.csv' #change dir to your project folder"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c3AMjVjZB2k1",
        "colab_type": "text"
      },
      "source": [
        "# 0. Exploring the dataset\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NBKi1QBaBvu6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Â Hend data importing cell \n",
        "\n",
        "df = pd.read_csv('/content/gdrive/My Drive/KTH courses/P4/NLP Language processing/project/data/train.csv')\n",
        "df.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rOOit2ZqBwEn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "405a1415-aef9-490d-af1f-2b0ae37d9f67"
      },
      "source": [
        "#Alex data importing cell\n",
        "\n",
        "df = pd.read_csv('/content/gdrive/My Drive/project/data/train.csv')\n",
        "df.head()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>qid1</th>\n",
              "      <th>qid2</th>\n",
              "      <th>question1</th>\n",
              "      <th>question2</th>\n",
              "      <th>is_duplicate</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>What is the step by step guide to invest in sh...</td>\n",
              "      <td>What is the step by step guide to invest in sh...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>What is the story of Kohinoor (Koh-i-Noor) Dia...</td>\n",
              "      <td>What would happen if the Indian government sto...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>6</td>\n",
              "      <td>How can I increase the speed of my internet co...</td>\n",
              "      <td>How can Internet speed be increased by hacking...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "      <td>8</td>\n",
              "      <td>Why am I mentally very lonely? How can I solve...</td>\n",
              "      <td>Find the remainder when [math]23^{24}[/math] i...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>9</td>\n",
              "      <td>10</td>\n",
              "      <td>Which one dissolve in water quikly sugar, salt...</td>\n",
              "      <td>Which fish would survive in salt water?</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id  qid1  qid2                                          question1  \\\n",
              "0   0     1     2  What is the step by step guide to invest in sh...   \n",
              "1   1     3     4  What is the story of Kohinoor (Koh-i-Noor) Dia...   \n",
              "2   2     5     6  How can I increase the speed of my internet co...   \n",
              "3   3     7     8  Why am I mentally very lonely? How can I solve...   \n",
              "4   4     9    10  Which one dissolve in water quikly sugar, salt...   \n",
              "\n",
              "                                           question2  is_duplicate  \n",
              "0  What is the step by step guide to invest in sh...             0  \n",
              "1  What would happen if the Indian government sto...             0  \n",
              "2  How can Internet speed be increased by hacking...             0  \n",
              "3  Find the remainder when [math]23^{24}[/math] i...             0  \n",
              "4            Which fish would survive in salt water?             0  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7WDHSoKmBwud",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Shuffle the data\n",
        "\n",
        "df = df.sample(frac=1, random_state = 0).reset_index(drop=True)\n",
        "\n",
        "# Create train, validation and test datasets\n",
        "train_portion = 0.7\n",
        "val_portion = 0.15\n",
        "test_portion = 0.15\n",
        "\n",
        "train_idx = int(train_portion * df.shape[0])\n",
        "val_idx = int((train_portion + val_portion) * df.shape[0])\n",
        "\n",
        "train = df[:train_idx]\n",
        "val = df[train_idx:val_idx]\n",
        "test = df[val_idx:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "scPk5uTgBxJF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 316
        },
        "outputId": "ed4e0fd3-bee4-4586-f423-967a1e2e7d3e"
      },
      "source": [
        "is_dup = train['is_duplicate'].value_counts()\n",
        "print(\"Class 0: \", is_dup[0], \" Class1: \", is_dup[1])\n",
        "plt.figure(figsize=(8,4))\n",
        "sns.barplot(is_dup.index, is_dup.values, alpha=0.8)\n",
        "plt.ylabel('Number of Occurrences', fontsize=12)\n",
        "plt.xlabel('Is Duplicate', fontsize=12)\n",
        "plt.title('Checking the balance of the classes')\n",
        "plt.show()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Class 0:  178510  Class1:  104493\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAg4AAAEZCAYAAAD/gK2HAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nZmZm2Vw4mJmZWbb/A2TE7n1wsRXoAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 576x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0FAp3P5kBxeY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# balancing the training set\n",
        "class0 = train[train['is_duplicate']==0].sample(n=is_dup[1], random_state=1)\n",
        "class1 = train[train['is_duplicate']==1]\n",
        "train = pd.concat([class0, class1])\n",
        "\n",
        "train = train.sample(frac = 1).reset_index(drop = True)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GZ-8TmjBBxzi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 331
        },
        "outputId": "fa2b8be4-f175-4a86-dc02-477b611afd85"
      },
      "source": [
        "\n",
        "# HIstogram number of words\n",
        "\n",
        "temp = train['question1'].apply(lambda x: len(x.split()) if type(x) == str else np.nan)\n",
        "\n",
        "temp2 = train['question2'].apply(lambda x: len(x.split()) if type(x) == str else np.nan)\n",
        "\n",
        "temp = pd.concat([temp, temp2]).dropna()\n",
        "\n",
        "sns.distplot(temp, kde=False)\n",
        "plt.legend()\n",
        "plt.title(\"Distribution number of words in questions\")\n",
        "plt.xlabel(\"Number of words\")\n",
        "plt.ylabel(\"frequency\")\n",
        "\n",
        "plt.show()\n",
        "plt.clf()\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "No handles with labels found to put in legend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZsAAAEWCAYAAACwtjr+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4UyhA2lOCB37",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 331
        },
        "outputId": "f724b86e-3563-402f-a755-814685535c14"
      },
      "source": [
        "# detail same plot\n",
        "sns.distplot(temp[temp < 50], kde=False)\n",
        "plt.legend()\n",
        "plt.title(\"Distribution number of words in questions\")\n",
        "plt.xlabel(\"Number of words\")\n",
        "plt.ylabel(\"frequency\")\n",
        "\n",
        "plt.show()\n",
        "plt.clf()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "No handles with labels found to put in legend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZUAAAEWCAYAAACufwpNAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nVhoHFTMzK42DipmZlcZBxczMSvP/AR33PezOdbejAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sd7MqdQ9CPbP",
        "colab_type": "text"
      },
      "source": [
        "# 1.Random Forest\n",
        "\n",
        "see papers: http://papers.www2017.com.au.s3-website-ap-southeast-2.amazonaws.com/proceedings/p1221.pdf \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bdG0-JkSgGKA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Embedding file, Alex path\n",
        "EMBEDDING_FILE = '/content/gdrive/My Drive/project/embeddings/GoogleNews-vectors-negative300.bin'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yeypnWA8gabJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Embbeding file, Hend path\n",
        "EMBEDDING_FILE = '/content/gdrive/My Drive/KTH courses/P4/NLP Language processing/project/data/GoogleNews-vectors-negative300.bin.gz'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dkcoIQLKCCS4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "b88c746e-d5e5-4905-8b4e-f64f02f0b39b"
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nGIxOZBvCCn2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Tokenization of datasets\n",
        "train['q1_tokens'] = train['question1'].apply(lambda x: word_tokenize(x) if type(x)==str else np.nan)\n",
        "train['q2_tokens'] = train['question2'].apply(lambda x: word_tokenize(x) if type(x)==str else np.nan)\n",
        "\n",
        "val['q1_tokens'] = val['question1'].apply(lambda x: word_tokenize(x) if type(x)==str else np.nan)\n",
        "val['q2_tokens'] = val['question2'].apply(lambda x: word_tokenize(x) if type(x)==str else np.nan)\n",
        "\n",
        "test['q1_tokens'] = test['question1'].apply(lambda x: word_tokenize(x) if type(x)==str else np.nan)\n",
        "test['q2_tokens'] = test['question2'].apply(lambda x: word_tokenize(x) if type(x)==str else np.nan)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iSKRVyLDaiTC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "237bb1c8-1758-444b-b44b-0a156cf34e49"
      },
      "source": [
        "# delete stopwords\n",
        "nltk.download('stopwords')\n",
        "STOP_WORDS = set(stopwords.words('english'))\n",
        "train['q1_tokens'] = train['q1_tokens'].apply(lambda x: [w for w in x if w not in STOP_WORDS] if isinstance(x, list) else x)\n",
        "train['q2_tokens'] = train['q2_tokens'].apply(lambda x: [w for w in x if w not in STOP_WORDS] if isinstance(x, list) else x)\n",
        "\n",
        "val['q1_tokens'] = val['q1_tokens'].apply(lambda x: [w for w in x if w not in STOP_WORDS] if isinstance(x, list) else x)\n",
        "val['q2_tokens'] = val['q2_tokens'].apply(lambda x: [w for w in x if w not in STOP_WORDS] if isinstance(x, list) else x)\n",
        "\n",
        "test['q1_tokens'] = test['q1_tokens'].apply(lambda x: [w for w in x if w not in STOP_WORDS] if isinstance(x, list) else x)\n",
        "test['q2_tokens'] = test['q2_tokens'].apply(lambda x: [w for w in x if w not in STOP_WORDS] if isinstance(x, list) else x)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NoOA31mfau7R",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "530cfb44-b95f-4e65-db8a-8f81e4dc3328"
      },
      "source": [
        "# Create gensim dictionary to allow BoW representation\n",
        "dctr = Dictionary(train['q1_tokens'].dropna())\n",
        "dctr.add_documents(train['q2_tokens'].dropna())\n",
        "\n",
        "# Create tf-idf model\n",
        "corpus = train['q1_tokens'].tolist() + train['q2_tokens'].tolist()\n",
        "corpus = [dctr.doc2bow(sent) for sent in corpus if type(sent)==list]\n",
        "model = TfidfModel(corpus)\n",
        "\n",
        "# Apply tf-idf to all the questions in the training set, creating new columns\n",
        "train['q1_tfidf'] = train['q1_tokens'].apply(lambda x: model[dctr.doc2bow(x)] if type(x)==list else np.nan)\n",
        "train['q2_tfidf'] = train['q2_tokens'].apply(lambda x: model[dctr.doc2bow(x)] if type(x)==list else np.nan)\n",
        "\n",
        "val['q1_tfidf'] = val['q1_tokens'].apply(lambda x: model[dctr.doc2bow(x)] if type(x)==list else np.nan)\n",
        "val['q2_tfidf'] = val['q2_tokens'].apply(lambda x: model[dctr.doc2bow(x)] if type(x)==list else np.nan)\n",
        "\n",
        "test['q1_tfidf'] = test['q1_tokens'].apply(lambda x: model[dctr.doc2bow(x)] if type(x)==list else np.nan)\n",
        "test['q2_tfidf'] = test['q2_tokens'].apply(lambda x: model[dctr.doc2bow(x)] if type(x)==list else np.nan)\n",
        "\n",
        "train.head()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>qid1</th>\n",
              "      <th>qid2</th>\n",
              "      <th>question1</th>\n",
              "      <th>question2</th>\n",
              "      <th>is_duplicate</th>\n",
              "      <th>q1_tokens</th>\n",
              "      <th>q2_tokens</th>\n",
              "      <th>q1_tfidf</th>\n",
              "      <th>q2_tfidf</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>282133</td>\n",
              "      <td>202489</td>\n",
              "      <td>22665</td>\n",
              "      <td>Which is the most used programming language in...</td>\n",
              "      <td>Which computer language is the most used?</td>\n",
              "      <td>1</td>\n",
              "      <td>[Which, used, programming, language, world, cu...</td>\n",
              "      <td>[Which, computer, language, used, ?]</td>\n",
              "      <td>[(0, 8.939333220814905e-05), (1, 0.25172827630...</td>\n",
              "      <td>[(0, 0.00011748551739742082), (1, 0.3308348179...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>339444</td>\n",
              "      <td>467106</td>\n",
              "      <td>52236</td>\n",
              "      <td>What inspires you the most in your life?</td>\n",
              "      <td>What inspires you most to do something in your...</td>\n",
              "      <td>0</td>\n",
              "      <td>[What, inspires, life, ?]</td>\n",
              "      <td>[What, inspires, something, life, ?]</td>\n",
              "      <td>[(0, 0.00010188545055962743), (7, 0.0918185888...</td>\n",
              "      <td>[(0, 8.923360106546234e-05), (7, 0.08041681396...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>97747</td>\n",
              "      <td>162580</td>\n",
              "      <td>162581</td>\n",
              "      <td>Is it that tough to get into IIT?</td>\n",
              "      <td>Is it tough to get into IIT?</td>\n",
              "      <td>1</td>\n",
              "      <td>[Is, tough, get, IIT, ?]</td>\n",
              "      <td>[Is, tough, get, IIT, ?]</td>\n",
              "      <td>[(0, 9.687800669647881e-05), (10, 0.5666653365...</td>\n",
              "      <td>[(0, 9.687800669647881e-05), (10, 0.5666653365...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>26633</td>\n",
              "      <td>49539</td>\n",
              "      <td>49540</td>\n",
              "      <td>What practical applications might evolve from ...</td>\n",
              "      <td>Are there any practical applications for the d...</td>\n",
              "      <td>1</td>\n",
              "      <td>[What, practical, applications, might, evolve,...</td>\n",
              "      <td>[Are, practical, applications, discovery, Higg...</td>\n",
              "      <td>[(0, 4.940339845879814e-05), (7, 0.04452206182...</td>\n",
              "      <td>[(0, 5.377422683391227e-05), (15, 0.4594452729...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>283052</td>\n",
              "      <td>86534</td>\n",
              "      <td>403086</td>\n",
              "      <td>What has been the single most important life d...</td>\n",
              "      <td>What is the biggest/most important decision yo...</td>\n",
              "      <td>1</td>\n",
              "      <td>[What, single, important, life, decision, made...</td>\n",
              "      <td>[What, biggest/most, important, decision, took...</td>\n",
              "      <td>[(0, 7.353793438842072e-05), (7, 0.06627196838...</td>\n",
              "      <td>[(0, 4.846161191254096e-05), (7, 0.04367332913...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       id    qid1    qid2                                          question1  \\\n",
              "0  282133  202489   22665  Which is the most used programming language in...   \n",
              "1  339444  467106   52236           What inspires you the most in your life?   \n",
              "2   97747  162580  162581                  Is it that tough to get into IIT?   \n",
              "3   26633   49539   49540  What practical applications might evolve from ...   \n",
              "4  283052   86534  403086  What has been the single most important life d...   \n",
              "\n",
              "                                           question2  is_duplicate  \\\n",
              "0          Which computer language is the most used?             1   \n",
              "1  What inspires you most to do something in your...             0   \n",
              "2                       Is it tough to get into IIT?             1   \n",
              "3  Are there any practical applications for the d...             1   \n",
              "4  What is the biggest/most important decision yo...             1   \n",
              "\n",
              "                                           q1_tokens  \\\n",
              "0  [Which, used, programming, language, world, cu...   \n",
              "1                          [What, inspires, life, ?]   \n",
              "2                           [Is, tough, get, IIT, ?]   \n",
              "3  [What, practical, applications, might, evolve,...   \n",
              "4  [What, single, important, life, decision, made...   \n",
              "\n",
              "                                           q2_tokens  \\\n",
              "0               [Which, computer, language, used, ?]   \n",
              "1               [What, inspires, something, life, ?]   \n",
              "2                           [Is, tough, get, IIT, ?]   \n",
              "3  [Are, practical, applications, discovery, Higg...   \n",
              "4  [What, biggest/most, important, decision, took...   \n",
              "\n",
              "                                            q1_tfidf  \\\n",
              "0  [(0, 8.939333220814905e-05), (1, 0.25172827630...   \n",
              "1  [(0, 0.00010188545055962743), (7, 0.0918185888...   \n",
              "2  [(0, 9.687800669647881e-05), (10, 0.5666653365...   \n",
              "3  [(0, 4.940339845879814e-05), (7, 0.04452206182...   \n",
              "4  [(0, 7.353793438842072e-05), (7, 0.06627196838...   \n",
              "\n",
              "                                            q2_tfidf  \n",
              "0  [(0, 0.00011748551739742082), (1, 0.3308348179...  \n",
              "1  [(0, 8.923360106546234e-05), (7, 0.08041681396...  \n",
              "2  [(0, 9.687800669647881e-05), (10, 0.5666653365...  \n",
              "3  [(0, 5.377422683391227e-05), (15, 0.4594452729...  \n",
              "4  [(0, 4.846161191254096e-05), (7, 0.04367332913...  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FRzxkDnoc9VU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "1673d79e-998d-41d7-e074-168669192fd3"
      },
      "source": [
        "# Create question embeddings as the weighted average of word2vec embeddings, using tfidf for weighting\n",
        "\n",
        "# Load embeddings\n",
        "\n",
        "word2vec = KeyedVectors.load_word2vec_format(EMBEDDING_FILE, binary=True)\n",
        "\n",
        "\n",
        "def tfidf_emb(tfidf_weights, dctr, embeddings):\n",
        "  return np.mean([w[1] * embeddings[dctr[w[0]]] for w in tfidf_weights if dctr[w[0]] in embeddings.vocab], axis = 0) if isinstance(tfidf_weights, list) else np.nan\n",
        "\n",
        "train['q1_emb'] = train['q1_tfidf'].apply(lambda x: tfidf_emb(x, dctr, word2vec))\n",
        "train['q2_emb'] = train['q2_tfidf'].apply(lambda x: tfidf_emb(x, dctr, word2vec))\n",
        "\n",
        "val['q1_emb'] = val['q1_tfidf'].apply(lambda x: tfidf_emb(x, dctr, word2vec))\n",
        "val['q2_emb'] = val['q2_tfidf'].apply(lambda x: tfidf_emb(x, dctr, word2vec))\n",
        "\n",
        "test['q1_emb'] = test['q1_tfidf'].apply(lambda x: tfidf_emb(x, dctr, word2vec))\n",
        "test['q2_emb'] = test['q2_tfidf'].apply(lambda x: tfidf_emb(x, dctr, word2vec))\n",
        "\n",
        "word2vec = None"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/numpy/core/fromnumeric.py:3118: RuntimeWarning: Mean of empty slice.\n",
            "  out=out, **kwargs)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nyyox63QCDNg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "outputId": "9cc51998-5270-44be-9f9c-d6c2d6bc7819"
      },
      "source": [
        "#Â preparing the features \n",
        "\n",
        "\n",
        "#series of all the questions in the training set \n",
        "train_qs = pd.Series(train['question1'].tolist() + train['question2'].tolist()).astype(str)\n",
        "print(\"Question: \",train_qs[1])\n",
        "\n",
        "#length of the questions provided in the train set\n",
        "len_qs_train = train_qs.apply(lambda x: len(x.split(' ')))\n",
        "print(\"lengh of the question: \",len_qs_train[1])\n",
        "\n",
        "qmarks = np.mean(train_qs.apply(lambda x: '?' in x))\n",
        "print(\"The pourcentage of questions including '?' : \",qmarks)\n",
        "\n",
        "fullstop = np.mean(train_qs.apply(lambda x: '.' in x))\n",
        "print(\"The pourcentage of questions including '.' : \",fullstop)\n",
        "\n",
        "capital_first = np.mean(train_qs.apply(lambda x: x[0].isupper()))\n",
        "print(\"The pourcentage of questions starting with a capital letter is: \",capital_first)\n",
        "\n",
        "capitals = np.mean(train_qs.apply(lambda x: max([y.isupper() for y in x])))\n",
        "print(\"The pourcentage of questions including capital letters : \",capitals)\n",
        "\n",
        "numbers = np.mean(train_qs.apply(lambda x: max([y.isdigit() for y in x])))\n",
        "print(\"The mean max numbers of digits in  of questions including numbers : \",numbers)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Question:  What inspires you the most in your life?\n",
            "lengh of the question:  8\n",
            "The pourcentage of questions including '?' :  0.9988994478099011\n",
            "The pourcentage of questions including '.' :  0.05602049898079297\n",
            "The pourcentage of questions starting with a capital letter is:  0.9983228541624798\n",
            "The pourcentage of questions including capital letters :  0.9995502091049161\n",
            "The mean max numbers of digits in  of questions including numbers :  0.11622070377920052\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3kIY3in2CDe4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# If a word appears only once, we ignore it completely (likely a typo)\n",
        "# Epsilon defines a smoothing constant, which makes the effect of extremely rare words smaller\n",
        "def get_weight(count, eps=10000, min_count=1):\n",
        "    if count < min_count:\n",
        "        return 0\n",
        "    else:\n",
        "        return 1 / (count + eps)\n",
        "\n",
        "eps = 5000 \n",
        "words = [item for sentence in (train['q1_tokens'].dropna().tolist() + train['q2_tokens'].dropna().tolist()) for item in sentence]\n",
        "counts = Counter(words)\n",
        "weights = {word: get_weight(count) for word, count in counts.items()}\n",
        "\n",
        "stops = set(stopwords.words('english'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kgoLBv8yCDup",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        },
        "outputId": "c4c616ac-2a7b-42ae-c740-0e4ed95cf689"
      },
      "source": [
        "def sim_tfidf(a, b):\n",
        "  if not isinstance(a, list) or not isinstance(b, list) or len(a) + len(b) == 0:\n",
        "    return np.nan\n",
        "  \n",
        "  max_idx = max([w[0] for w in a] + [w[0] for w in b])+1\n",
        "  \n",
        "  a_vec = np.zeros(max_idx)\n",
        "  b_vec = np.zeros(max_idx)\n",
        "  \n",
        "  for w in a:\n",
        "    a_vec[w[0]] = w[-1]\n",
        "    \n",
        "  for w in b:\n",
        "    b_vec[w[0]] = w[-1]\n",
        "  return cosine_similarity(a_vec.reshape(1,-1),b_vec.reshape(1,-1))[0][0]\n",
        "\n",
        "\n",
        "def word_match_share(row):\n",
        "    q1words = {}\n",
        "    q2words = {}\n",
        "    for word in str(row['question1']).lower().split():\n",
        "        if word not in stops:\n",
        "            q1words[word] = 1\n",
        "    for word in str(row['question2']).lower().split():\n",
        "        if word not in stops:\n",
        "            q2words[word] = 1\n",
        "    if len(q1words) == 0 or len(q2words) == 0:\n",
        "        # The computer-generated chaff includes a few questions that are nothing but stopwords\n",
        "        return 0\n",
        "    shared_words_in_q1 = [w for w in q1words.keys() if w in q2words]\n",
        "    shared_words_in_q2 = [w for w in q2words.keys() if w in q1words]\n",
        "    R = (len(shared_words_in_q1) + len(shared_words_in_q2))/(len(q1words) + len(q2words))\n",
        "    \n",
        "    return R\n",
        "\n",
        "\n",
        "def tfidf_word_match_share(row):\n",
        "    q1words = {}\n",
        "    q2words = {}\n",
        "    for word in str(row['question1']).lower().split():\n",
        "        if word not in stops:\n",
        "            q1words[word] = 1\n",
        "    for word in str(row['question2']).lower().split():\n",
        "        if word not in stops:\n",
        "            q2words[word] = 1\n",
        "    if len(q1words) == 0 or len(q2words) == 0:\n",
        "        # The computer-generated chaff includes a few questions that are nothing but stopwords\n",
        "        return 0\n",
        "    \n",
        "    shared_weights = [weights.get(w, 0) for w in q1words.keys() if w in q2words] + [weights.get(w, 0) for w in q2words.keys() if w in q1words]\n",
        "    total_weights = [weights.get(w, 0) for w in q1words] + [weights.get(w, 0) for w in q2words]\n",
        "    \n",
        "    R = np.sum(shared_weights) / np.sum(total_weights)\n",
        "    return R\n",
        "\n",
        "  \n",
        "def sim_emb(q1_emb, q2_emb):\n",
        "  \n",
        "  if type(q1_emb) != np.ndarray or type(q2_emb) != np.ndarray:\n",
        "    return np.nan\n",
        "  \n",
        "  return cosine_similarity(q1_emb.reshape(1,-1), q2_emb.reshape(1,-1))[0][0]\n",
        "\n",
        "  \n",
        "  \n",
        "  \n",
        "  \n",
        "train_word_match = train.apply(word_match_share, axis=1, raw=True)\n",
        "\n",
        "tfidf_train_word_match = train.apply(tfidf_word_match_share, axis=1, raw=True)\n",
        "\n",
        "tfidf_similarity = train.apply(lambda row: sim_tfidf(row['q1_tfidf'], row['q2_tfidf']), axis=1, raw=True)\n",
        "\n",
        "emb_similarity = train.apply(lambda row: sim_emb(row['q1_emb'], row['q2_emb']), axis=1, raw=True)\n",
        "\n",
        "\n",
        "x_train = pd.DataFrame()\n",
        "x_train['word_match'] = train_word_match\n",
        "x_train['tfidf_word_match'] = tfidf_train_word_match\n",
        "x_train['tfidf_similarity'] = tfidf_similarity\n",
        "x_train['emb_similarity'] = emb_similarity\n",
        "x_train['q1_emb'] = train['q1_emb']\n",
        "x_train['q2_emb'] = train['q2_emb']\n",
        "x_train['id'] = train['id']\n",
        "x_train['is_duplicate'] = train['is_duplicate']\n",
        "\n",
        "x_train = x_train.dropna().reset_index(drop = True)\n",
        "\n",
        "y_train = x_train['is_duplicate'].values\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "val_word_match = val.apply(word_match_share, axis=1, raw=True)\n",
        "tfidf_val_word_match = val.apply(tfidf_word_match_share, axis=1, raw=True)\n",
        "tfidf_val_similarity = val.apply(lambda row: sim_tfidf(row['q1_tfidf'], row['q2_tfidf']), axis=1, raw=True)\n",
        "\n",
        "emb_val_similarity = val.apply(lambda row: sim_emb(row['q1_emb'], row['q2_emb']), axis=1, raw=True)\n",
        "\n",
        "\n",
        "x_val = pd.DataFrame()\n",
        "x_val['word_match'] = val_word_match\n",
        "x_val['tfidf_word_match'] = tfidf_val_word_match\n",
        "x_val['tfidf_similarity'] = tfidf_val_similarity\n",
        "x_val['emb_similarity'] = emb_val_similarity\n",
        "x_val['q1_emb'] = val['q1_emb']\n",
        "x_val['q2_emb'] = val['q2_emb']\n",
        "x_val['is_duplicate'] = val['is_duplicate']\n",
        "x_val = x_val.dropna().reset_index(drop = True)\n",
        "\n",
        "y_val = x_val['is_duplicate'].values\n",
        "\n",
        "x_val['id'] = val['id']\n",
        "\n",
        "predictors=['word_match','tfidf_word_match', 'tfidf_similarity', 'emb_similarity']\n",
        "target='is_duplicate'\n",
        "\n",
        "\n",
        "X_train= x_train[predictors]\n",
        "y_train = x_train[target]\n",
        "X_val = x_val[predictors]\n",
        "#y_test = x_test[target]\n",
        "\n",
        "#X=np.array(X).reshape(-1,1)\n",
        "#y=np.array(y).reshape(-1,1)\n",
        "#X= X.tolist()\n",
        "#y= y.tolist()\n",
        "\n",
        "\n",
        "def calculate_logloss(y_true, y_pred):\n",
        "    loss_cal = log_loss(y_true, y_pred)\n",
        "    return loss_cal\n",
        "\n",
        "\n",
        "clf= RandomForestClassifier(n_estimators=500, criterion='gini', max_depth=None, min_samples_split=2, min_samples_leaf=100, min_weight_fraction_leaf=0.0, max_features='sqrt', max_leaf_nodes=None, bootstrap=True, oob_score=True, n_jobs=1, random_state=1, verbose=0, warm_start=False, class_weight=None)\n",
        "clf.fit(X_train,y_train)\n",
        "##\n",
        "accuracy=clf.score(X_val,y_val)\n",
        "print(\"Random Forest\",accuracy)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:53: RuntimeWarning: invalid value encountered in long_scalars\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:53: RuntimeWarning: invalid value encountered in double_scalars\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:53: RuntimeWarning: invalid value encountered in long_scalars\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:53: RuntimeWarning: invalid value encountered in double_scalars\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Random Forest 0.743886252778976\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-eb7ff47d9d82>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Random Forest\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m \u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'X_test' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "52_N0TjtCb3t",
        "colab_type": "text"
      },
      "source": [
        "#Â 2. Siamese network \n",
        "https://towardsdatascience.com/one-shot-learning-with-siamese-networks-using-keras-17f34e75bb3d\n",
        "\n",
        "https://becominghuman.ai/siamese-networks-algorithm-applications-and-pytorch-implementation-4ffa3304c18"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LWiEVYt9DVyq",
        "colab_type": "text"
      },
      "source": [
        "## 2.1 Importing libraries and data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_foU9I6-CD_J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Â importing libraries \n",
        "\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "from time import time\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from gensim.models import KeyedVectors\n",
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "import itertools\n",
        "import datetime\n",
        "\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, Embedding, LSTM, Lambda\n",
        "import keras.backend as K\n",
        "from keras.optimizers import Adadelta\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "\n",
        "# File paths\n",
        "TRAIN_CSV = '/content/gdrive/My Drive/KTH courses/P4/NLP Language processing/project/data/train.csv'\n",
        "TEST_CSV = '/content/gdrive/My Drive/KTH courses/P4/NLP Language processing/project/data/test.csv'\n",
        "EMBEDDING_FILE = '/content/gdrive/My Drive/KTH courses/P4/NLP Language processing/project/data/GoogleNews-vectors-negative300.bin.gz'\n",
        "MODEL_SAVING_DIR = '/content/gdrive/My Drive/KTH courses/P4/NLP Language processing/project/Models/malstm_trained.h5'\n",
        "\n",
        "# Load training and test set\n",
        "train_df = pd.read_csv(TRAIN_CSV)\n",
        "#test_df = pd.read_csv(TRAIN_CSV)\n",
        "test_df = train_df[:1000]\n",
        "\n",
        "stops = set(stopwords.words('english'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5374y42CCZn3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create embedding matrix\n",
        "\n",
        "def text_to_word_list(text):\n",
        "    ''' Pre process and convert texts to a list of words '''\n",
        "    \n",
        "    text = str(text)\n",
        "    text = text.lower()\n",
        "\n",
        "    # Clean the text\n",
        "    text = re.sub(r\"[^A-Za-z0-9^,!.\\/'+-=]\", \" \", text) #delete special characters\n",
        "    text = re.sub(r\"what's\", \"what is \", text) # replace what's by what is\n",
        "    text = re.sub(r\"\\'s\", \" \", text)\n",
        "    text = re.sub(r\"\\'ve\", \" have \", text)\n",
        "    text = re.sub(r\"can't\", \"cannot \", text)\n",
        "    text = re.sub(r\"n't\", \" not \", text)\n",
        "    text = re.sub(r\"i'm\", \"i am \", text)\n",
        "    text = re.sub(r\"\\'re\", \" are \", text)\n",
        "    text = re.sub(r\"\\'d\", \" would \", text)\n",
        "    text = re.sub(r\"\\'ll\", \" will \", text)\n",
        "    text = re.sub(r\",\", \" \", text)\n",
        "    text = re.sub(r\"\\.\", \" \", text)\n",
        "    text = re.sub(r\"!\", \" ! \", text)\n",
        "    text = re.sub(r\"\\/\", \" \", text)\n",
        "    text = re.sub(r\"\\^\", \" ^ \", text)\n",
        "    text = re.sub(r\"\\+\", \" + \", text)\n",
        "    text = re.sub(r\"\\-\", \" - \", text)\n",
        "    text = re.sub(r\"\\=\", \" = \", text)\n",
        "    text = re.sub(r\"'\", \" \", text)\n",
        "    text = re.sub(r\"(\\d+)(k)\", r\"\\g<1>000\", text)\n",
        "    text = re.sub(r\":\", \" : \", text)\n",
        "    text = re.sub(r\" e g \", \" eg \", text)\n",
        "    text = re.sub(r\" b g \", \" bg \", text)\n",
        "    text = re.sub(r\" u s \", \" american \", text)\n",
        "    text = re.sub(r\"\\0s\", \"0\", text)\n",
        "    text = re.sub(r\" 9 11 \", \"911\", text)\n",
        "    text = re.sub(r\"e - mail\", \"email\", text)\n",
        "    text = re.sub(r\"j k\", \"jk\", text)\n",
        "    text = re.sub(r\"\\s{2,}\", \" \", text)\n",
        "\n",
        "    text = text.split()\n",
        "\n",
        "    return text\n",
        "\n",
        "# Prepare embedding\n",
        "vocabulary = dict()\n",
        "inverse_vocabulary = ['<unk>']  # '<unk>' will never be used, it is only a placeholder for the [0, 0, ....0] embedding\n",
        "word2vec = KeyedVectors.load_word2vec_format(EMBEDDING_FILE, binary=True)\n",
        "\n",
        "questions_cols = ['question1', 'question2']\n",
        "\n",
        "# Iterate over the questions only of both training and test datasets\n",
        "for dataset in [train_df, test_df]:\n",
        "    for index, row in dataset.iterrows():\n",
        "\n",
        "        # Iterate through the text of both questions of the row\n",
        "        for question in questions_cols:\n",
        "\n",
        "            q2n = []  # q2n -> question numbers representation\n",
        "            for word in text_to_word_list(row[question]):\n",
        "\n",
        "                # Check for unwanted words\n",
        "                if word in stops and word not in word2vec.vocab:\n",
        "                    continue\n",
        "\n",
        "                if word not in vocabulary:\n",
        "                    vocabulary[word] = len(inverse_vocabulary)\n",
        "                    q2n.append(len(inverse_vocabulary))\n",
        "                    inverse_vocabulary.append(word)\n",
        "                else:\n",
        "                    q2n.append(vocabulary[word])\n",
        "\n",
        "            # Replace questions as word to question as number representation\n",
        "            dataset.set_value(index, question, q2n)\n",
        "            \n",
        "embedding_dim = 300\n",
        "embeddings = 1 * np.random.randn(len(vocabulary) + 1, embedding_dim)  # This will be the embedding matrix\n",
        "embeddings[0] = 0  # So that the padding will be ignored\n",
        "\n",
        "# Build the embedding matrix\n",
        "for word, index in vocabulary.items():\n",
        "    if word in word2vec.vocab:\n",
        "        embeddings[index] = word2vec.word_vec(word)\n",
        "\n",
        "del word2vec\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VlVx-AEoCZ9T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "max_seq_length = max(train_df.question1.map(lambda x: len(x)).max(),\n",
        "                     train_df.question2.map(lambda x: len(x)).max(),\n",
        "                     test_df.question1.map(lambda x: len(x)).max(),\n",
        "                     test_df.question2.map(lambda x: len(x)).max())\n",
        "\n",
        "# Split to train validation\n",
        "validation_size = 40000\n",
        "training_size = len(train_df) - validation_size\n",
        "\n",
        "X = train_df[questions_cols]\n",
        "Y = train_df['is_duplicate']\n",
        "\n",
        "X_train, X_validation, Y_train, Y_validation = train_test_split(X, Y, test_size=validation_size)\n",
        "\n",
        "# Split to dicts\n",
        "X_train = {'left': X_train.question1, 'right': X_train.question2}\n",
        "X_validation = {'left': X_validation.question1, 'right': X_validation.question2}\n",
        "X_test = {'left': test_df.question1, 'right': test_df.question2}\n",
        "\n",
        "# Convert labels to their numpy representations\n",
        "Y_train = Y_train.values\n",
        "Y_validation = Y_validation.values\n",
        "\n",
        "# Zero padding\n",
        "for dataset, side in itertools.product([X_train, X_validation], ['left', 'right']):\n",
        "    dataset[side] = pad_sequences(dataset[side], maxlen=max_seq_length)\n",
        "\n",
        "# Make sure everything is ok\n",
        "assert X_train['left'].shape == X_train['right'].shape\n",
        "assert len(X_train['left']) == len(Y_train)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WdNy-Y8GCaUo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Build the model\n",
        "\n",
        "\n",
        "# Model variables\n",
        "n_hidden = 50\n",
        "gradient_clipping_norm = 1.25\n",
        "batch_size = 100 # prevously 64\n",
        "n_epoch = 25\n",
        "\n",
        "def exponent_neg_manhattan_distance(left, right):\n",
        "    ''' Helper function for the similarity estimate of the LSTMs outputs'''\n",
        "    return K.exp(-K.sum(K.abs(left-right), axis=1, keepdims=True))\n",
        "\n",
        "# The visible layer\n",
        "left_input = Input(shape=(max_seq_length,), dtype='int32')\n",
        "right_input = Input(shape=(max_seq_length,), dtype='int32')\n",
        "\n",
        "embedding_layer = Embedding(len(embeddings), embedding_dim, weights=[embeddings], input_length=max_seq_length, trainable=False)\n",
        "\n",
        "# Embedded version of the inputs\n",
        "encoded_left = embedding_layer(left_input)\n",
        "encoded_right = embedding_layer(right_input)\n",
        "\n",
        "# Since this is a siamese network, both sides share the same LSTM\n",
        "shared_lstm = LSTM(n_hidden)\n",
        "\n",
        "left_output = shared_lstm(encoded_left)\n",
        "right_output = shared_lstm(encoded_right)\n",
        "\n",
        "# Calculates the distance as defined by the MaLSTM model\n",
        "malstm_distance = Lambda(function=lambda x: exponent_neg_manhattan_distance(x[0], x[1]),output_shape=lambda x: (x[0][0], 1))([left_output, right_output])\n",
        "\n",
        "# Pack it all up into a model\n",
        "malstm = Model([left_input, right_input], [malstm_distance])\n",
        "\n",
        "# Adadelta optimizer, with gradient clipping by norm\n",
        "optimizer = Adadelta(clipnorm=gradient_clipping_norm)\n",
        "\n",
        "malstm.compile(loss='mean_squared_error', optimizer=optimizer, metrics=['accuracy'])\n",
        "\n",
        "# Start training\n",
        "training_start_time = time()\n",
        "\n",
        "malstm_trained = malstm.fit([X_train['left'], X_train['right']], Y_train, batch_size=batch_size, nb_epoch=n_epoch,\n",
        "                            validation_data=([X_validation['left'], X_validation['right']], Y_validation))\n",
        "\n",
        "print(\"Training time finished.\\n{} epochs in {}\".format(n_epoch, datetime.timedelta(seconds=time()-training_start_time)))\n",
        "\n",
        "\n",
        "\n",
        "malstm_trained.save(MODEL_SAVING_DIR)  # creates a HDF5 file 'my_model.h5'\n",
        "# del model  # deletes the existing model\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n6wiaU6vCaqm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import load_model\n",
        "# returns a compiled model\n",
        "# identical to the previous one\n",
        "model = load_model('my_model.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3h1rRLNcCa7O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Plotting the results\n",
        "\n",
        "\n",
        "# Plot accuracy\n",
        "plt.plot(malstm_trained.history['acc'])\n",
        "plt.plot(malstm_trained.history['val_acc'])\n",
        "plt.title('Model Accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "# Plot loss\n",
        "plt.plot(malstm_trained.history['loss'])\n",
        "plt.plot(malstm_trained.history['val_loss'])\n",
        "plt.title('Model Loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Validation'], loc='upper right')\n",
        "plt.show()\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HgYE25IBEaTH",
        "colab_type": "text"
      },
      "source": [
        "#Â 3. GRU Deep Model\n",
        "\n",
        "Inspired by this Network Architecture\n",
        "\n",
        "https://www.linkedin.com/pulse/duplicate-quora-question-abhishek-thakur/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Ysw2dOfCbPQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create embedding matrix\n",
        "\n",
        "def text_to_word_list(text):\n",
        "    ''' Pre process and convert texts to a list of words '''\n",
        "    \n",
        "    text = str(text)\n",
        "    text = text.lower()\n",
        "\n",
        "    # Clean the text\n",
        "    text = re.sub(r\"[^A-Za-z0-9^,!.\\/'+-=]\", \" \", text) #delete special characters\n",
        "    text = re.sub(r\"what's\", \"what is \", text) # replace what's by what is\n",
        "    text = re.sub(r\"\\'s\", \" \", text)\n",
        "    text = re.sub(r\"\\'ve\", \" have \", text)\n",
        "    text = re.sub(r\"can't\", \"cannot \", text)\n",
        "    text = re.sub(r\"n't\", \" not \", text)\n",
        "    text = re.sub(r\"i'm\", \"i am \", text)\n",
        "    text = re.sub(r\"\\'re\", \" are \", text)\n",
        "    text = re.sub(r\"\\'d\", \" would \", text)\n",
        "    text = re.sub(r\"\\'ll\", \" will \", text)\n",
        "    text = re.sub(r\",\", \" \", text)\n",
        "    text = re.sub(r\"\\.\", \" \", text)\n",
        "    text = re.sub(r\"!\", \" ! \", text)\n",
        "    text = re.sub(r\"\\/\", \" \", text)\n",
        "    text = re.sub(r\"\\^\", \" ^ \", text)\n",
        "    text = re.sub(r\"\\+\", \" + \", text)\n",
        "    text = re.sub(r\"\\-\", \" - \", text)\n",
        "    text = re.sub(r\"\\=\", \" = \", text)\n",
        "    text = re.sub(r\"'\", \" \", text)\n",
        "    text = re.sub(r\"(\\d+)(k)\", r\"\\g<1>000\", text)\n",
        "    text = re.sub(r\":\", \" : \", text)\n",
        "    text = re.sub(r\" e g \", \" eg \", text)\n",
        "    text = re.sub(r\" b g \", \" bg \", text)\n",
        "    text = re.sub(r\" u s \", \" american \", text)\n",
        "    text = re.sub(r\"\\0s\", \"0\", text)\n",
        "    text = re.sub(r\" 9 11 \", \"911\", text)\n",
        "    text = re.sub(r\"e - mail\", \"email\", text)\n",
        "    text = re.sub(r\"j k\", \"jk\", text)\n",
        "    text = re.sub(r\"\\s{2,}\", \" \", text)\n",
        "\n",
        "    text = text.split()\n",
        "\n",
        "    return text\n",
        "\n",
        "# Prepare embedding\n",
        "vocabulary = dict()\n",
        "inverse_vocabulary = ['<unk>']  # '<unk>' will never be used, it is only a placeholder for the [0, 0, ....0] embedding\n",
        "word2vec = KeyedVectors.load_word2vec_format(EMBEDDING_FILE, binary=True)\n",
        "\n",
        "questions_cols = ['q1_tokens', 'q2_tokens']\n",
        "\n",
        "# Iterate over the questions only of both training and test datasets\n",
        "for dataset in [train, val, test]:\n",
        "    for index, row in dataset.iterrows():\n",
        "\n",
        "        # Iterate through the text of both questions of the row\n",
        "        for question in questions_cols:\n",
        "          \n",
        "            if type(row[question]) != float:\n",
        "\n",
        "              for word in row[question]:\n",
        "\n",
        "                  # Check for unwanted words\n",
        "                  if word not in word2vec.vocab:\n",
        "                      continue\n",
        "\n",
        "                  if word not in vocabulary:\n",
        "                      vocabulary[word] = len(inverse_vocabulary)\n",
        "                      inverse_vocabulary.append(word)\n",
        "            # Replace questions as word to question as number representation\n",
        "              q2n = [vocabulary[w] for w in row[question] if w in vocabulary]\n",
        "            else:\n",
        "              q2n = []\n",
        "              \n",
        "            dataset.set_value(index, question, q2n)\n",
        "            \n",
        "embedding_dim = 300\n",
        "embeddings = 1 * np.random.randn(len(vocabulary) + 1, embedding_dim)  # This will be the embedding matrix\n",
        "embeddings[0] = 0  # So that the padding will be ignored\n",
        "\n",
        "# Build the embedding matrix\n",
        "for word, index in vocabulary.items():\n",
        "    if word in word2vec.vocab:\n",
        "        embeddings[index] = word2vec.word_vec(word)\n",
        "\n",
        "del word2vec\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WTsVdSYWHYA4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create training and validation set for keras model\n",
        "\n",
        "max_seq_length = max(train.q1_tokens.map(lambda x: len(x)).max(),\n",
        "                     train.q2_tokens.map(lambda x: len(x)).max(),\n",
        "                     val.q1_tokens.map(lambda x: len(x)).max(),\n",
        "                     val.q2_tokens.map(lambda x: len(x)).max())\n",
        "\n",
        "\n",
        "X_train = train[questions_cols]\n",
        "Y_train = train['is_duplicate']\n",
        "\n",
        "X_validation = val[questions_cols]\n",
        "Y_validation = val['is_duplicate']\n",
        "\n",
        "# Split to dicts\n",
        "X_train = {'left': X_train.q1_tokens, 'right': X_train.q2_tokens}\n",
        "X_validation = {'left': X_validation.q1_tokens, 'right': X_validation.q2_tokens}\n",
        "# X_test = {'left': test.q1_tokens, 'right': test.q2_tokens}\n",
        "\n",
        "# Convert labels to their numpy representations\n",
        "Y_train = Y_train.values\n",
        "Y_validation = Y_validation.values\n",
        "\n",
        "# Zero padding\n",
        "for dataset, side in itertools.product([X_train, X_validation], ['left', 'right']):\n",
        "    dataset[side] = pad_sequences(dataset[side], maxlen=max_seq_length)\n",
        "\n",
        "# Make sure everything is ok\n",
        "assert X_train['left'].shape == X_train['right'].shape\n",
        "assert len(X_train['left']) == len(Y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5_ta9F7kHZjQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import Model\n",
        "from keras.layers.recurrent import GRU\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.layers import Input, Dense\n",
        "from keras.layers import Dropout, Flatten, Embedding\n",
        "import keras\n",
        "\n",
        "\n",
        "def define_network(embeddings, max_seq_length):\n",
        "\n",
        "\n",
        "    input_1 = Input((max_seq_length,), dtype = 'int32', name = 'q1_input') # Input question 1\n",
        "    input_2 = Input((max_seq_length,), dtype = 'int32', name = 'q2_input') # Input question 2\n",
        "\n",
        "    embedding_layer = Embedding(len(embeddings), 300, weights=[embeddings], input_length=max_seq_length, trainable=False)\n",
        "    \n",
        "    embd_1 = embedding_layer(input_1)\n",
        "    embd_2 = embedding_layer(input_2)\n",
        "    \n",
        "    gru_shared_layer = GRU(300, dropout = 0.2, recurrent_dropout = 0.2, name = 'GRU_common')\n",
        "    gru_1 = gru_shared_layer(embd_1)\n",
        "    gru_2 = gru_shared_layer(embd_2)\n",
        "\n",
        "    merge = keras.layers.merge.concatenate([gru_1, gru_2])\n",
        "    \n",
        "    bn = BatchNormalization()(merge)\n",
        "    dense = Dense(300, activation = 'relu', name = \"relu_dense\")(bn)\n",
        "    drop = Dropout(0.2)(dense)\n",
        "    bn2 = BatchNormalization()(drop)\n",
        "    output = Dense(1, activation = 'sigmoid', name = 'output_dense')(bn2)\n",
        "\n",
        "\n",
        "    model = Model(inputs = [input_1, input_2], outputs = output)\n",
        "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tdsxEB1XHbpu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 64\n",
        "n_epoch = 20"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YWzZFseoHcYt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = define_network(embeddings, max_seq_length)\n",
        "\n",
        "history = model.fit([X_train['left'], X_train['right']], Y_train, batch_size = batch_size,\n",
        "                    epochs = n_epoch, validation_data = ([X_validation['right'], X_validation['left']], Y_validation))\n",
        "\n",
        "model.save('model_alex.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k7ohGQTqHoQX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# analysis results + plots"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}